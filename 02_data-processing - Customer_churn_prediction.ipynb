{"cells":[{"cell_type":"markdown","source":["# Create, evaluate, and score a churn prediction model"],"metadata":{},"id":"98e321e3-7797-4a8d-9822-2f1084ba2e2f"},{"cell_type":"markdown","source":["## Introduction\n\nIn this notebook series, you'll see a Microsoft Fabric data science workflow with an end-to-end example. The scenario is to build a model to predict whether bank customers would churn or not. The churn rate, also known as the rate of attrition refers to the rate at which bank customers stop doing business with the bank.\n\nThe main steps in this notebook series are:\n\n**Notebook 1: Data Ingestion** <br>\n&nbsp; &nbsp; 1. Install custom libraries <br>\n&nbsp; &nbsp; 2. Load the data <br>\n\n**Notebook 2: Data Preparation** <br>\n&nbsp; &nbsp; 3. Understand and process the data through exploratory data analysis and demonstrate the use of Fabric Data Wrangler feature.\n\n**Notebook 3: Model Training**<br>\n&nbsp; &nbsp; 4. Train machine learning models using `Scikit-Learn` and `LightGBM`, and track experiments using MLflow and Fabric Autologging feature.<br>\n&nbsp; &nbsp; 5. Evaluate and save the final machine learning model.<br>\n\n**Notebook 4: Inference**<br>\n&nbsp; &nbsp; 6. load the best model to run predicitons.<br>\n\n\n    \n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"faa52bd2-a2ca-4cc4-90c2-e37b69df136d"},{"cell_type":"markdown","source":["## Prerequisites\n","- [Add a lakehouse](https://aka.ms/fabric/addlakehouse) to this notebook. You will be downloading data from a public blob, then storing the data in the lakehouse. "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"1eb8ee2b-ba0c-43b3-9d9d-8654067ec748"},{"cell_type":"markdown","source":["### Imports and parameters"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f54f3fb-f2d5-4145-946f-c3d402da16c1"},{"cell_type":"code","source":["import os\n","import requests\n","from pathlib import Path, PurePath, PurePosixPath"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2f1b8d68-5bf3-4bb0-bb73-af23eccc97ff"},{"cell_type":"markdown","source":["Define these parameters, so that you can use this notebook with different datasets or [Assign parameters values from a pipeline](https://learn.microsoft.com/en-us/fabric/data-engineering/author-execute-notebook#assign-parameters-values-from-a-pipeline)."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"372fb863-0f73-4a35-bb11-dc22256964bc"},{"cell_type":"code","source":["# Specify the storage location for the data set\n","INPUT_TABLE_NAME = 'bronze.churn'\n","TARGET = \"Exited\" # Dependent (target) attribute\n","OUTPUT_TABLE_NAME = 'churn'"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"8024548c-a089-4d50-b2b3-2fa989ec7568"},{"cell_type":"markdown","source":["## Step 3: Perform exploratory data analysis"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"44379940-befb-4b21-a377-41ba78366ca3"},{"cell_type":"markdown","source":["### Read raw data from the lakehouse\n","\n","This code reads raw delta table data from the **Table** section of the lakehouse, and adds more columns for different date parts."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"1f22364a-ccb5-4686-9ac0-1120b859fbd5"},{"cell_type":"code","source":["df = spark.sql(f\"SELECT * FROM {INPUT_TABLE_NAME}\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"2cfd34fd-047c-44d0-884a-4941482bd5fb"},{"cell_type":"markdown","source":["### Create a pandas DataFrame from the dataset\n","\n","This code converts the Spark DataFrame to a pandas DataFrame, for easier processing and visualization:"],"metadata":{},"id":"51a5c225-f482-4703-9b91-5cb6ba1970ae"},{"cell_type":"code","source":["df = df.toPandas()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d550d94b-552e-41fd-b23f-3caa064f842a"},{"cell_type":"markdown","source":["### Display raw data\n","\n","Explore the raw data with `display`, calculate some basic statistics, and show chart views. You must first import the required libraries for data visualization - for example, [seaborn](https://seaborn.pydata.org/). Seaborn is a Python data visualization library, and it provides a high-level interface to build visuals on dataframes and arrays."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"cf0eb500-e05e-4e62-b297-0189a31d1037"},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as mticker\n","from matplotlib import rc, rcParams\n","import numpy as np\n","import pandas as pd\n","import itertools\n","\n","sns.set_theme(style=\"whitegrid\", palette=\"tab10\", rc={\"figure.figsize\": (9, 6)})"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"73290de5-ed00-415a-b546-5f4a7586cff7"},{"cell_type":"code","source":["display(df, summary=True)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"7e4e1172-c117-4a3e-8d40-e3c983f750c9"},{"cell_type":"markdown","source":["### Use Data Wrangler to perform initial data cleaning\n","\n","Launch Data Wrangler directly from the notebook to explore and transform pandas dataframes. At the notebook ribbon **Data** tab, use the Data Wrangler dropdown prompt to browse the activated pandas DataFrames available for editing. Select the DataFrame you want to open in Data Wrangler.\n","\n","\n","><mark>NOTE:</mark> \\\n",">Data Wrangler cannot be opened while the notebook kernel is busy. The cell execution must finish before you launch Data Wrangler.\n",">[Learn more about Data Wrangler](https://aka.ms/fabric/datawrangler).\n","\n","\n","<br>\n","\n","<img src=\"https://sdkstorerta.blob.core.windows.net/churnblob/select_datawrangler.png\"  width=\"40%\" height=\"10%\" title=\"Screenshot shows where to access the Data Wrangler.\">"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d5f34273-fae3-4de1-ac85-1807146a121c"},{"cell_type":"markdown","source":["After the Data Wrangler launches, a descriptive overview of the data panel is generated, as shown in the following images. The overview includes information about the dimension of the DataFrame, any missing values, etc. You can use Data Wrangler to generate the script to drop the rows with missing values, the duplicate rows and the columns with specific names. Then, you can copy the script into a cell. The next cell shows that copied script.\n","\n","<img style=\"float: left;\" src=\"https://sdkstorerta.blob.core.windows.net/churnblob/menu_datawrangler.png\"  width=\"45%\" height=\"10%\" title=\"Screenshot shows Data Wrangler menu.\"> \n","<img style=\"float: left;\" src=\"https://sdkstorerta.blob.core.windows.net/churnblob/missing_data_datawrangler.png\"  width=\"45%\" height=\"10%\" title=\"Screenshot shows Data Wrangler missing data display.\">\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"eacf1362-b8fc-403d-a0f4-42b3c369d303"},{"cell_type":"markdown","source":["```python\n","# Von Data Wrangler für Pandas DataFrame generierter Code\n","\n","def clean_data(df):\n","    # Löschen doppelter Zeilen in Spalten: 'RowNumber', 'CustomerId'\n","    df = df.drop_duplicates(subset=['RowNumber', 'CustomerId'])\n","    # Verwerfen von Zeilen mit fehlenden Daten in allen Spalten\n","    df = df.dropna()\n","    # Löschen der Spalten: 'RowNumber', 'CustomerId', 'Surname'\n","    df = df.drop(columns=['RowNumber', 'CustomerId', 'Surname'])\n","    return df\n","\n","df_clean = clean_data(df.copy())\n","df_clean.head()\n","```"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"780797cb-f428-42bb-b9a6-b377f41ade90"},{"cell_type":"code","source":["def clean_data(df):\n","    # Drop duplicate rows\n","    df = df.drop_duplicates(subset=['RowNumber', 'CustomerId'])\n","    # Drop rows with any missing data\n","    df = df.dropna()\n","    # Drop index columns\n","    df = df.drop(columns=['RowNumber', 'CustomerId', 'Surname'])\n","    return df\n","\n","\n","df_clean = clean_data(df)\n","df_clean.shape"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"18014588-2616-4753-8c17-b115aab07310"},{"cell_type":"markdown","source":["### Determine attributes\n","\n","This code determines the categorical, numerical, and target attributes:"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2922660b-dd45-4c2d-8a75-7431fefffb0c"},{"cell_type":"code","source":["# Determine the categorical attributes\n","categorical_variables = [col for col in df_clean.columns if df_clean[col].dtype == \"O\" \n","                        or df_clean[col].nunique() <= 5 \n","                        and col != TARGET ]\n","print(categorical_variables)\n","# Determine the numerical attributes\n","numeric_variables = [col for col in df_clean.columns if col not in categorical_variables\n","                    and col != TARGET\n","]\n","print(numeric_variables)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3adb4922-607e-4f4e-bdb2-bda535acb94c"},{"cell_type":"markdown","source":["### Show the five-number summary\n","\n","Show the five-number summary (minimum score, first quartile, median, third quartile, and maximum score) for the numerical attributes by using box plots:"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"0640a89c-6a64-4978-89f1-5a45cdd1303e"},{"cell_type":"code","source":["df_num_cols = df_clean[numeric_variables]\n","sns.set(font_scale=0.7)\n","fig, axes = plt.subplots(\n","    nrows=2, ncols=3, gridspec_kw=dict(hspace=0.3), figsize=(17, 8)\n",")\n","fig.tight_layout()\n","for ax, col in zip(axes.flatten(), df_num_cols.columns):\n","    sns.boxplot(x=df_num_cols[col], color=\"green\", ax=ax)\n","# fig.suptitle('visualize and compare the distribution and central tendency of numerical attributes', color = 'k', fontsize = 12)\n","fig.delaxes(axes[1, 2])"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f45982d4-de27-43b5-b826-e93730d7e66c"},{"cell_type":"markdown","source":["Show the distribution of exited versus non-exited customers across the categorical attributes:"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a320fd15-64eb-493e-9b60-500ad4535435"},{"cell_type":"code","source":["attr_list = [\n","    \"Geography\",\n","    \"Gender\",\n","    \"HasCrCard\",\n","    \"IsActiveMember\",\n","    \"NumOfProducts\",\n","    \"Tenure\",\n","]\n","fig, axarr = plt.subplots(2, 3, figsize=(15, 4))\n","for ind, item in enumerate(attr_list):\n","    sns.countplot(x=item, hue=TARGET, data=df_clean, ax=axarr[ind % 2][ind // 2])\n","fig.subplots_adjust(hspace=0.7)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c4811cab-6cdc-4014-a0ab-8f90232e6603"},{"cell_type":"markdown","source":["Use a histogram to show the frequency distribution of numerical attributes:"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5075fddc-1cce-4c64-8d17-499a309440d7"},{"cell_type":"code","source":["columns = df_num_cols.columns[: len(df_num_cols.columns)]\n","fig = plt.figure()\n","fig.set_size_inches(18, 8)\n","length = len(columns)\n","for i, j in itertools.zip_longest(columns, range(length)):\n","    plt.subplot((length // 2), 3, j + 1)\n","    plt.subplots_adjust(wspace=0.2, hspace=0.5)\n","    df_num_cols[i].hist(bins=21, edgecolor=\"black\")\n","    plt.title(i)\n","fig = fig.suptitle('Distribution of numerical attributes', color = 'b' ,fontsize = 14)\n","plt.show()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8626b081-a301-4cfa-9db3-38ab8524879d"},{"cell_type":"markdown","source":["### Perform feature engineering \n","\n","This feature engineering generates new attributes based on the current attributes:"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"945e1166-0e88-4baa-ac2c-b56b7eeeb7c4"},{"cell_type":"code","source":["# limit tenure to time where person is of legal age\n","df_clean[\"Tenure\"] = np.where((df_clean[\"Age\"]-18) < df_clean[\"Tenure\"], df_clean[\"Age\"]-18, df_clean[\"Tenure\"])\n","# create a feature tenure telative to age\n","df_clean[\"NewTenure\"] = np.where(df_clean[\"Age\"] > 18, df_clean[\"Tenure\"]/(df_clean[\"Age\"]-18), 0)\n","\n","df_clean.describe(include='all')"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e8a3e0c5-db7b-44bf-b11b-8d323934e151"},{"cell_type":"markdown","source":["### Use Data Wrangler to perform one-hot encoding\n","\n","With the same steps to launch Data Wrangler, as discussed earlier, use the Data Wrangler to perform one-hot encoding. This cell shows the copied generated script for one-hot encoding:\n","\n","<img style=\"float: left;\" src=\"https://sdkstorerta.blob.core.windows.net/churnblob/1hotencoding_data_wrangler.png\"  width=\"45%\" height=\"20%\" title=\"Screenshot shows one-hot encoding in the Data Wrangler\"> \n","<img style=\"float: left;\" src=\"https://sdkstorerta.blob.core.windows.net/churnblob/1hotencoding_selectcolumns_data_wrangler.png\"  width=\"45%\" height=\"20%\" title=\"Screenshot shows selection of columns in the Data Wrangler.\">\n","\n","\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"76be9b0c-3f67-461f-8bd7-cd0450b2bc1e"},{"cell_type":"markdown","source":["```python\n","# Von Data Wrangler für Pandas DataFrame generierter Code\n","\n","import pandas as pd\n","\n","def clean_data(df):\n","    # 1-aus-n-Codierungsspalten: 'Geography', 'Gender'\n","    for column in ['Geography', 'Gender']:\n","        insert_loc = df.columns.get_loc(column)\n","        df = pd.concat([df.iloc[:,:insert_loc], pd.get_dummies(df.loc[:, [column]]), df.iloc[:,insert_loc+1:]], axis=1)\n","    return df\n","\n","df_clean = clean_data(df_clean.copy())\n","df_clean.head()\n","```"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2388d349-f114-4aa1-ac0b-89b22590f300"},{"cell_type":"code","source":["# we use the shorter pandas version\n","df_clean = pd.get_dummies(df_clean, columns=['Geography', 'Gender'])\n","\n","df_clean.describe(include='all')"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a1f24530-c228-4b44-8eda-361309ed4bff"},{"cell_type":"markdown","source":["### Create a delta table to generate the Power BI report"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5c4f77d9-1167-460e-a3ba-3268acafd285"},{"cell_type":"code","source":["# Create a PySpark DataFrame from pandas\n","output_table_name = f\"silver/{OUTPUT_TABLE_NAME}\"\n","sparkDF = spark.createDataFrame(df_clean)\n","sparkDF.write.mode(\"overwrite\").format(\"delta\").save(f\"Tables/{output_table_name}\")\n","print(f\"Spark DataFrame saved to delta table: {output_table_name}\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9061366a-dd4f-43e1-9b81-081f43d20378"},{"cell_type":"markdown","source":["### Summary of observations from the exploratory data analysis\n","\n","- Most of the customers are from France. Spain has the lowest churn rate, compared to France and Germany.\n","- Most of the customers have credit cards.\n","- Some customers are both over the age of 60 and have credit scores below 400. However, they can't be considered as outliers\n","- Very few customers have more than two of the bank's products.\n","- Inactive customers have a higher churn rate\n","- Gender and tenure years have little impact on a customer's decision to close a bank account\n"],"metadata":{},"id":"1efc8976-b1e1-4c85-b4ee-8dd29040ca02"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"notebook_environment":{},"nteract":{"version":"nteract-front-end@1.0.0"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"synapse_widget":{"version":"0.1","state":{}},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"},"enableDebugMode":false}},"dependencies":{"lakehouse":{},"environment":{}}},"nbformat":4,"nbformat_minor":5}