{"cells":[{"cell_type":"markdown","source":["# ML model scoring with PREDICT"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f192ae1d-64a5-44ec-8de7-05c778fee6a4"},{"cell_type":"markdown","source":["## Introduction\n","\n","In this notebook series, you'll see a Microsoft Fabric data science workflow with an end-to-end example. The scenario is to build a model to predict whether bank customers would churn or not. The churn rate, also known as the rate of attrition refers to the rate at which bank customers stop doing business with the bank.\n","\n","The main steps in this notebook series are:\n","\n","\n","- Notebook 1: Data Ingestion \n","    1. Install custom libraries\n","    2. Load the data \n","\n","- Notebook 2:<br>\n","    3. Understand and process the data through exploratory data analysis and demonstrate the use of Fabric Data Wrangler feature. \n","\n","- Notebook 3: <br>\n","    4. Train machine learning models using `Scikit-Learn` and `LightGBM`, and track experiments using MLflow and Fabric Autologging feature.\n","    5. Evaluate and save the final machine learning model\n","\n","- Notebool 4:<br>\n","\t6. load the best model to run predicitons.\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8bd3361a-8351-4bbb-94bd-0fc8a2718958"},{"cell_type":"markdown","source":["## Generate batch inference from the ML model's item page\n","\n","From the ML model's item page, you can choose either of the following options to start generating batch predictions for a specific model version with PREDICT. \n","\n","With **Apply this model in wizart**, you can use the UI to generate a customised PREDICT code as notebook or code sniped. Altenatively, **Copy code to apply** can generate a code template that you can copy into a notebook and customize the parameters yourself. For more detail, we recommend visiting the official [Microsoft Fabric documentation](https://learn.microsoft.com/en-us/fabric/data-science/model-scoring-predict#generate-predict-code-from-an-ml-models-item-page).\n","\n","![image-alt-text](https://learn.microsoft.com/en-us/fabric/data-science/media/model-scoring-predict/apply-model.png#lightbox)\n","\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b8232757-871e-495d-9232-670ef56fd1b2"},{"cell_type":"markdown","source":["### Use a guided UI experience\n\nThe guided UI experience walks you through steps to:\n\n1. Select source data for scoring\n2. Map the data correctly to your ML model's inputs\n3. Specify the destination for your model's outputs\n4. Create a notebook that uses `transform` to generate and store prediction results\n\nIn our case, this generates the following code:\n\n```python\nimport mlflow\nfrom synapse.ml.predict import MLFlowTransformer\n    \ndf = spark.read.format(\"delta\").load(\n    \"abfss://fd38eb65-3cc4-4868-82bf-bc7b79c7b550@onelake.dfs.fabric.microsoft.com/2702e363-4951-4ca0-bb07-7517c5337666/Tables/df_test\"\n)\n    \nmodel = MLFlowTransformer(\n    inputCols=[\"CreditScore\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"HasCrCard\",\"IsActiveMember\",\"EstimatedSalary\",\"NewTenure\",\"Geography_France\",\"Geography_Germany\",\"Geography_Spain\", \"Gender_Female\",\"Gender_Male\"],\n    outputCol=\"predictions\",\n    modelName=\"lgbm_sm\",\n    modelVersion=1\n)\ndf = model.transform(df)\n    \ndf.write.format('delta').mode(\"overwrite\").save(\n    \"abfss://fd38eb65-3cc4-4868-82bf-bc7b79c7b550@onelake.dfs.fabric.microsoft.com/2702e363-4951-4ca0-bb07-7517c5337666/Tables/customer_churn_test_predictions\"\n)\n\n```"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"906dd0cf-24ba-45f4-9b92-e3cc0d43aa60"},{"cell_type":"markdown","source":["### Use a customizable code template\nTo use a code template for generating batch predictions:\n\n1. Go to the item page for a given ML model version.\n2. Select **Copy code to apply** from the **Apply this version** dropdown. The selection allows you to copy a customizable code template.\n\nIn our case, this generates the following template:\n\n```python\nimport mlflow\nfrom synapse.ml.predict import MLFlowTransformer\n    \ndf = spark.read.format(\"delta\").load(\n    <INPUT_TABLE> # Your input table filepath here\n)\n    \nmodel = MLFlowTransformer(\n    inputCols=[\"CreditScore\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"HasCrCard\",\"IsActiveMember\",\"EstimatedSalary\",\"NewTenure\",\"Geography_France\",\"Geography_Germany\",\"Geography_Spain\",\"Gender_Female\",\"Gender_Male\"], # Your input columns here\n    outputCol=\"predictions\", # Your new column name here\n    modelName=\"lgbm_sm\", # Your model name here\n    modelVersion=1 # Your model version here\n)\ndf = model.transform(df)\n    \ndf.write.format('delta').mode(\"overwrite\").save(\n    <OUTPUT_TABLE> # Your output table filepath here\n)\n```"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c67d44a7-0956-4267-8f63-fcc2b1f2f642"},{"cell_type":"markdown","source":["### Imports and Parameters"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2896701a-1d10-40ba-a284-02ffad893178"},{"cell_type":"code","source":["import mlflow\n","from synapse.ml.predict import MLFlowTransformer\n","from pyspark.ml.feature import SQLTransformer \n","from pyspark.sql.functions import col, pandas_udf, udf, lit"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"69b7e39d-d9d3-44c4-a316-f95c49e9f81a"},{"cell_type":"markdown","source":["Define these parameters, so that you can use this notebook with different datasets or [Assign parameters values from a pipeline](https://learn.microsoft.com/en-us/fabric/data-engineering/author-execute-notebook#assign-parameters-values-from-a-pipeline)."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e67f8b47-4b83-40a9-9f86-d0be022fc024"},{"cell_type":"code","source":["INPUT_TABLE_NAME = \"gold/churn_test\"\n","OUTPUT_TABLE_NAME = \"churn_prediction\"\n","MODEL_NAME = \"lgbm_sm\"\n","MODEL_VERSION = \"latest\""],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"35bc1361-2e9c-40e0-b7ac-5af656809e37"},{"cell_type":"markdown","source":["## Step 6: Run batch inference"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f43b510e-1dd9-4f06-946f-105c1b4fae46"},{"cell_type":"markdown","source":["## Load the test data"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8dd58da6-6468-4b9c-bcf4-a3bd402df91d"},{"cell_type":"code","source":["df_test = spark.read.format(\"delta\").load(f\"Tables/{INPUT_TABLE_NAME}\")\n","display(df_test.limit(5))"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"80a8499e-1d57-409f-a5a8-5ebece5e35d7"},{"cell_type":"markdown","source":["### Load ML model for inference"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"43a226d1-3f83-40e4-8011-739e3382dc64"},{"cell_type":"markdown","source":["To create an `MLFlowTransformer` object for generating batch predictions, you must perform the following actions:\n\n- `inputCols`: specify which columns you need as model inputs,\n- `outputCol`: choose a name for the new output column, and\n- `modelName` and `modelVersion`: provide the correct model name and model version for generating those predictions.\n\n<mark>NOTE:\nYou can get more information about a python object by using mouseover or calling it with the `help()` function.</mark>\n\n```python\n>> help(MLFlowTransformer)\n\nHelp on class MLFlowTransformer in module synapse.ml.predict.MLFlowTransformer:\n\nclass MLFlowTransformer(pyspark.ml.base.Transformer, pyspark.ml.param.shared.HasInputCols, pyspark.ml.param.shared.HasOutputCol, synapse.ml.logging.LoggerFactory.SynapseMLLogging)\n |  MLFlowTransformer(inputCols: List[str] = None, outputCol: str = None, modelName: str = None, modelVersion: str = 'latest', trackingUri: str = None, registerModel: bool = True, flattenOutput: bool = True) -> pyspark.ml.base.Transformer\n |  \n |  Args:\n |      inputCols (str):  Columns to feed to the model\n |      outputCol (str): The column to add output predictions to\n |      modelName (str):  The name of the model in the model registry\n |      modelVersion (str):  The version of the model in the model registry\n |      trackingUri (str):  The location of the MLFlow tracking server\n |      registerModel (bool): Whether to register the model with the PREDICT SQL command\n |      flattenOutput (bool): Whether to Flatten Predict Output\n |  \n |  Method resolution order:\n |      MLFlowTransformer\n |      pyspark.ml.base.Transformer\n |      pyspark.ml.param.shared.HasInputCols\n |      pyspark.ml.param.shared.HasOutputCol\n |      pyspark.ml.param.Params\n |      pyspark.ml.util.Identifiable\n |      synapse.ml.logging.LoggerFactory.SynapseMLLogging\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, inputCols: List[str] = None, outputCol: str = None, modelName: str = None, modelVersion: str = 'latest', trackingUri: str = None, registerModel: bool = True, flattenOutput: bool = True) -> pyspark.ml.base.Transformer\n |      Parameters\n |      ----------\n ...\n\n```"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"67d7df17-0521-40d5-b099-3fe72e0f998d"},{"cell_type":"code","source":["# Define the model URI\n","model_uri = f\"models:/{MODEL_NAME}/{MODEL_VERSION}\"\n","# Load the model\n","model = mlflow.pyfunc.load_model(model_uri)\n","# Access the model's signature\n","signature = model.metadata.get_input_schema()\n","\n","print('Model input columns are:', signature.input_names())"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"94f265de-3f87-40b5-97f9-696f358d508e"},{"cell_type":"code","source":["model = MLFlowTransformer(\n","    inputCols=signature.input_names(),\n","    outputCol='predictions',\n","    modelName=MODEL_NAME,\n","    modelVersion=MODEL_VERSION # If you want to apply a specific model version, you should specify it here.\n",")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6be7e06d-20f0-4ef4-bf45-8d359076b1f2"},{"cell_type":"markdown","source":["### PREDICT with the Transformer API\n","\n","The following code calls the PREDICT function using the Transformer API."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ba5a288b-4a15-40b6-a9ca-06b7a787478a"},{"cell_type":"code","source":["predictions = model.transform(df_test)\n","display(predictions)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"8426386c-bc39-46aa-93cb-f01eb5382bb3"},{"cell_type":"markdown","source":["### PREDICT with the Spark SQL API\n","The following code calls the PREDICT function using the Spark SQL API."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e1f9873f-4ddd-444e-9f43-f81405d65c14"},{"cell_type":"code","source":["# Substitute \"model_name\", \"model_version\", and \"features\" below with values for your own model name, model version, and feature columns\n","model_name = 'lgbm_sm'\n","model_version = 'latest'\n","features = signature.input_names()\n","\n","sqlt = SQLTransformer().setStatement( \n","    f\"SELECT PREDICT('{MODEL_NAME}/{MODEL_VERSION}', {','.join(features)}) as predictions FROM __THIS__\")\n","\n","# Substitute \"X_test\" below with your own test dataset\n","display(sqlt.transform(df_test))"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"e7d66f4f-7ffe-4bfa-90ac-936c9d6d8d7f"},{"cell_type":"markdown","source":["### PREDICT with a user-defined function (UDF)\n","\n","The following code calls the PREDICT function using a PySpark UDF.\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"663bcb54-1e0a-4ffe-82af-8df5e66531dc"},{"cell_type":"code","source":["# Substitute \"model\" and \"features\" below with values for your own model name and feature columns\n","model_udf = model.to_udf()\n","features = signature.input_names()\n","\n","display(df_test.withColumn(\"predictions\", model_udf(*[col(f) for f in features])).limit(5))"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"65ba51ee-1faf-4a4a-8a9a-13e28cebd403"},{"cell_type":"markdown","source":["## Write model prediction results to the lakehouse\n","Once you have generated batch predictions, you can write the model results back to the lakehouse."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d6e90079-f3f7-4292-b7cc-92eecd691023"},{"cell_type":"code","source":["# Save predictions to lakehouse to be used for generating a Power BI report\n","table_name = f\"gold/{OUTPUT_TABLE_NAME}\"\n","predictions.write.format('delta').mode(\"overwrite\").save(f\"Tables/{table_name}\")\n","print(f\"Spark DataFrame saved to delta table: {table_name}\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4fab555f-b146-4e8a-93c1-9e23a344c6f8"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"de"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"version_major":2,"version_minor":0,"state":{"a553b81e73b94c61a171033bfe38a75f":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_aa30e9f8bcd14c6bb35bfa76d4800533","IPY_MODEL_29a49f27e0f54648a1e58817f748dac4","IPY_MODEL_276465af79244309b92d94e823266b7a"],"layout":"IPY_MODEL_c642a57a70ac4000b2196d7bebd45eab"}},"f5257d62692c493baff9271b1ffe9e0a":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"0c8815cfb0d74974875b26b5c8499f50":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"52f8d3e76ead49d797016e03cf2079a5":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"872fd1bf26824b1a867a13835c9fd7f5":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"Downloading artifacts: 100%","layout":"IPY_MODEL_ef357c8c5ff54370a4287ce00f63373f","style":"IPY_MODEL_e7302a86f94049e483a42f5b908f90c3"}},"9217e67aed3e468c9de351c38b61eeab":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_de62b1dc0ace4bbb9001280bdc2d01e2","IPY_MODEL_e06c7a1f05ee487bbd2571f626f18f98","IPY_MODEL_4aee933a50d74a5bb0933f1eb54a8883"],"layout":"IPY_MODEL_f5257d62692c493baff9271b1ffe9e0a"}},"7a0e827f727847eaad6dbe633f40d20b":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"53e8415a0ea44cb9b4ee06db3f0eabda":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"d56a26785db94dd08d633652925adf0b":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"276465af79244309b92d94e823266b7a":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 5/5 [00:00&lt;00:00, 52.28it/s]","layout":"IPY_MODEL_4722901b245246f38ae282b9a04cde8a","style":"IPY_MODEL_2d554b20b3074744b60018368fbb2e47"}},"20f631b3c0d24dbdbd92a08b79692258":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"4aee933a50d74a5bb0933f1eb54a8883":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 5/5 [00:00&lt;00:00, 59.23it/s]","layout":"IPY_MODEL_bc6e9753c7134a849dabcaaad37ae7c9","style":"IPY_MODEL_0c8815cfb0d74974875b26b5c8499f50"}},"4722901b245246f38ae282b9a04cde8a":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"307f02c86feb4051acf147ddb8c2a8a6":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"568d969374ba43c796ede36a82c61b25":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"ad1f5a342d3844f0b0b995b28bbfb93b":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"ef357c8c5ff54370a4287ce00f63373f":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"9e911101c2974647afa583b5eea43c2a":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"aa30e9f8bcd14c6bb35bfa76d4800533":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"Downloading artifacts: 100%","layout":"IPY_MODEL_52f8d3e76ead49d797016e03cf2079a5","style":"IPY_MODEL_20f631b3c0d24dbdbd92a08b79692258"}},"4946f9f4a848400c9d94c19aca6098e4":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"29a49f27e0f54648a1e58817f748dac4":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":5,"max":5,"bar_style":"success","style":"IPY_MODEL_1ecbf41b722648548a742d630602246b","layout":"IPY_MODEL_9e911101c2974647afa583b5eea43c2a"}},"c642a57a70ac4000b2196d7bebd45eab":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"e06c7a1f05ee487bbd2571f626f18f98":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":5,"max":5,"bar_style":"success","style":"IPY_MODEL_568d969374ba43c796ede36a82c61b25","layout":"IPY_MODEL_d56a26785db94dd08d633652925adf0b"}},"bc6e9753c7134a849dabcaaad37ae7c9":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"77c8cb1740ed4f83862c9880443027e1":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_872fd1bf26824b1a867a13835c9fd7f5","IPY_MODEL_93f59b23e3304eb7818dd7d9da85400b","IPY_MODEL_09b4d92cb7ed4342ace33f477bf1f1ed"],"layout":"IPY_MODEL_4946f9f4a848400c9d94c19aca6098e4"}},"09b4d92cb7ed4342ace33f477bf1f1ed":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 5/5 [00:00&lt;00:00,  3.66it/s]","layout":"IPY_MODEL_7a0e827f727847eaad6dbe633f40d20b","style":"IPY_MODEL_307f02c86feb4051acf147ddb8c2a8a6"}},"93f59b23e3304eb7818dd7d9da85400b":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":5,"max":5,"bar_style":"success","style":"IPY_MODEL_ad1f5a342d3844f0b0b995b28bbfb93b","layout":"IPY_MODEL_30cd8657cacd4496abd30491d8590e9d"}},"e7302a86f94049e483a42f5b908f90c3":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"2d554b20b3074744b60018368fbb2e47":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"0ed83565bc6f4ae69fd8c1e03e7e0da5":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"de62b1dc0ace4bbb9001280bdc2d01e2":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"Downloading artifacts: 100%","layout":"IPY_MODEL_53e8415a0ea44cb9b4ee06db3f0eabda","style":"IPY_MODEL_0ed83565bc6f4ae69fd8c1e03e7e0da5"}},"30cd8657cacd4496abd30491d8590e9d":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"1ecbf41b722648548a742d630602246b":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}}}}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"environment":{},"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}